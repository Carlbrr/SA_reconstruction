{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**\n",
    "- *obs. gitpython and pyvis packages installed in SA anaconda environment*\n",
    "- Cloning Zeeguu-API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (3.1.43)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from gitpython) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.1)\n",
      "Requirement already satisfied: pyvis in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from pyvis) (8.22.2)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from pyvis) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from pyvis) (3.0.4)\n",
      "Requirement already satisfied: networkx>=1.11 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from pyvis) (3.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from ipython>=5.3.0->pyvis) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\carl9\\anaconda3\\envs\\sa\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
      "Collecting ast\n",
      "  Using cached AST-0.0.2.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\carl9\\AppData\\Local\\Temp\\pip-install-fovpukee\\ast_0edaa66156b240beaef7b00b01a02f8d\\setup.py\", line 6, in <module>\n",
      "          README = codecs.open(os.path.join(here, 'AST/README'), encoding='utf8').read()\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<frozen codecs>\", line 918, in open\n",
      "      FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\carl9\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fovpukee\\\\ast_0edaa66156b240beaef7b00b01a02f8d\\\\AST/README'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# For new environement, install the following packages\n",
    "# install GitPython, and installs pyvis using the system's Python executable.\n",
    "#gitpyhon is used to interact with git repositories, and pyvis is used to visualize the graph.\n",
    "import sys\n",
    "sys.version\n",
    "!{sys.executable} -m pip install gitpython\n",
    "!{sys.executable} -m pip install pyvis\n",
    "!{sys.executable} -m pip install ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "# GitPython is a library that allows us to work easily with git from Python\n",
    "# https://gitpython.readthedocs.io/en/stable/tutorial.html\n",
    "\n",
    "# Let's declare a var for the path where we're going to download a repository\n",
    "# Warning: this must end in /\n",
    "CODE_ROOT_FOLDER=\"C:/Users/carl9/OneDrive/Skrivebord/SA_Individual_ZeeguuAPI/reconstruction/zeeguu-api/\"\n",
    "\n",
    "# If the file exists, it means we've already downloaded\n",
    "if not os.path.exists(CODE_ROOT_FOLDER):\n",
    "  Repo.clone_from(\"https://github.com/zeeguu/api\", CODE_ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**\n",
    "\n",
    "- **module_name_from_file_path()**  - *Extracts module from file path (.py files) e.g. ../core/model/user.py -> zeeguu.core.model.user*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting a module name from a file name\n",
    "def module_name_from_file_path(full_path):\n",
    "    file_name = full_path[len(CODE_ROOT_FOLDER):]\n",
    "    file_name = file_name.replace(\"/__init__.py\",\"\")\n",
    "    file_name = file_name.replace(\"/\",\".\")\n",
    "    file_name = file_name.replace(\".py\",\"\")\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Gathering**\n",
    "\n",
    "Utilize a defined grammar to parse and extract dependencies efficiently. Employ Abstract Syntax Trees (AST) to overcome the limitations posed by regex-based methods. This includes:\n",
    "1. Parse a file and generate AST (read file, then use ast package to generate AST from content)\n",
    "2. Define the grammar rules for the dependency extraction\n",
    "3. Traverse AST and collect dependencies based on grammar\n",
    "4. *define abstractions on different kinds of AST nodes*\n",
    "5. store dependencies, make em' ready for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Parse a Python file and return an AST node. e.g. parse_file('example.py')\n",
    "def file_to_ast_parser(f_path):\n",
    "    with open(f_path, 'r') as file:\n",
    "        code = file.read()\n",
    "    return ast.parse(code, filename=f_path)\n",
    "\n",
    "# Define Grammar rules for AST traversal of the pythcon code of a single file\n",
    "# could also do some counting here for more advanced analysis  / metric aggregati\n",
    "def collect_dependencies(abstract_syntax_tree):\n",
    "    dependencies = set()\n",
    "    module_attributes = dict()\n",
    "\n",
    "    #Define node types/grammar rules for the AST traversal:\n",
    "    def visit_Import(node):\n",
    "        for alias in node.names:\n",
    "            #collect the module names from the import statements (also handles the case of \"import os\" and \"import os as my_os alias\" woop)\n",
    "            dependencies.add(alias.asname if alias.asname else alias.name)\n",
    "            #print(\"ast Import: alias.name: \", alias.name)\n",
    "\n",
    "    def visit_ImportFrom(node):\n",
    "        if node.module:\n",
    "            dependencies.add(node.module)\n",
    "        # Collects the methods as well as all other attributes from the module\n",
    "        for alias in node.names:\n",
    "            module_attributes[alias.name] = node.module\n",
    "\n",
    "\n",
    "    # Recursively traverse the AST from the root node to all its children\n",
    "    def traverse(node):\n",
    "        if isinstance(node, ast.Import):\n",
    "            visit_Import(node)\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            visit_ImportFrom(node)\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            traverse(child)\n",
    "        \n",
    "    traverse(abstract_syntax_tree)\n",
    "    print(\"all module attributes: \", module_attributes)\n",
    "    used_dependencies = filter_dependencies(abstract_syntax_tree, dependencies, module_attributes)\n",
    "    return dependencies, used_dependencies\n",
    "    \n",
    "\n",
    "def filter_dependencies(abstract_syntax_tree, dependencies, module_attributes):\n",
    "    used_dependencies = set()\n",
    "\n",
    "    def filter_traverse(node, dependencies):\n",
    "        #ast.Name include variable names, function names, class names, module names, and other names used within the code.\n",
    "        \"\"\" if isinstance(node, ast.Name):\n",
    "            #node.id is the name of the Name node, e.g. \"os\" from \"import os\"\n",
    "            if node.id in dependencies:\n",
    "                print(\"ast Name: node.id: \", node.id)\n",
    "                used_dependencies.add(node.id)\n",
    "        \n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Name) and node.func.id in dependencies:\n",
    "                print(\"ast Call: node.func.id: \", node.func.id)\n",
    "                used_dependencies.add(node.func.id) \"\"\"\n",
    "        \n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Name): #and node.func.id in dependencies:\n",
    "                if node.func.id in module_attributes:\n",
    "                    print(\"ast Call: node.func.id: \", node.func.id)\n",
    "                    used_dependencies.add(module_attributes[node.func.id])\n",
    "                    \n",
    "            if isinstance(node.func, ast.Attribute) and isinstance(node.func.value, ast.Name) and node.func.value.id in dependencies:\n",
    "                print(\"ast Call: node.func.value.id: \", node.func.value.id)\n",
    "                used_dependencies.add(node.func.value.id)\n",
    "\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            filter_traverse(child, dependencies)\n",
    "\n",
    "\n",
    "    filter_traverse(abstract_syntax_tree, dependencies)\n",
    "    return used_dependencies\n",
    "\n",
    "#OOOOBS CARL. This does not solve the regex import problem. We are still limited by possible unused imports..\n",
    "# hmm i think i will need a more sophisticated approach to this. From this i could also collect some metrics on the codebase hm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dont think the above will work, i can't seem to manage the limitations using the ast module. It is much easier to make my own tokens...\n",
    "I can check if the nodes of the AST are imports etc.. but then this is just the same as gathering information with reggex.. im still bottlenecked at \n",
    "filtering unused and uncommented dependencies. \n",
    "To do it well enough, i would have to go through all code and look at which imported methods are called (import from) and which imported modules are called. This is difficult with just ast as i fx. dont catch functions calls in other calls (eg. print(func()))\n",
    "Also my current approach would only catch modules e.g. X.method(), not \"from .. import method -> method()\" as the method itself is not recorded as a dependency but only the module from which it is imported hmm.\n",
    "\n",
    "\n",
    "Okay, now i also collect the functions that has been imported from modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all module attributes:  {'request': 'urllib', 'load_configuration_or_abort': 'zeeguu.config.loader'}\n",
      "ast Call: node.func.value.id:  np\n",
      "ast Call: node.func.value.id:  ast\n",
      "ast Call: node.func.id:  load_configuration_or_abort\n",
      "all dep {'ast', 'zeeguu.config.loader', 'os', 'np', 'urllib'}\n",
      "used dep {'ast', 'np', 'zeeguu.config.loader'}\n",
      "unused dep:  {'urllib', 'os'}\n"
     ]
    }
   ],
   "source": [
    "#Testing the traversal of the AST\n",
    "\n",
    "ast_tree = file_to_ast_parser(\"C:/Users/carl9/OneDrive/Skrivebord/SA_Individual_ZeeguuAPI/test.py\")\n",
    "dependencies, used_dependencies = collect_dependencies(ast_tree)\n",
    "#dependencies = collect_dependencies(ast_tree)\n",
    "print(\"all dep\", dependencies)\n",
    "print(\"used dep\", used_dependencies)\n",
    "print(\"unused dep: \", dependencies - used_dependencies)\n",
    "\n",
    "#Okay for tomorrow: with this approach i still dont filter outcommented imports and outcommented calls... \n",
    "# I think i will need to do some regex magic to filter out the outcommented lines before i parse the file, but then \n",
    "# i wont be able to trace the \"unused\" dependencies.. Maybe i need to tokenize everything on my own, this ast approach might get a little too complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**\n",
    "- polymetrics views?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IoT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
